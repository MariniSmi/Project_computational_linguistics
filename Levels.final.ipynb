{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Для начала скачаем все нужные библиотеки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B6Nw3wczDQVb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e2585337f6a4df7857e611d4991fb33",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-21 08:57:37 INFO: Downloaded file to C:\\Users\\Марина\\stanza_resources\\resources.json\n",
            "2025-06-21 08:57:37 INFO: Downloading default packages for language: en (English) ...\n",
            "2025-06-21 08:57:38 INFO: File exists: C:\\Users\\Марина\\stanza_resources\\en\\default.zip\n",
            "2025-06-21 08:57:42 INFO: Finished downloading models and saved to C:\\Users\\Марина\\stanza_resources\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import codecs\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk import sent_tokenize\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "import stanza\n",
        "stanza.download(\"en\")\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import pickle\n",
        "import json\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Определим рабочую директорию и скорректируем ее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Марина\\OneDrive\\Desktop\\Компьютерная лингвистика\\Python\\Проект\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('c:/Users/Марина/OneDrive/Desktop/Компьютерная лингвистика/Python/Проект/корпус_текстов')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['A1', 'A1_lemmas.txt', 'A1_tokens.txt', 'A2', 'A2_lemmas.txt', 'A2_tokens.txt', 'B1', 'B1_lemmas.txt', 'B1_tokens.txt', 'B2', 'B2_lemmas.txt', 'B2_tokens.txt', 'C1', 'C1_lemmas.txt', 'C1_tokens.txt', 'analyzing_dependencies.json', 'bigrams_tokens.json', 'dependency_analysis.csv', 'dependency_analysis.xlsx', 'lemmatized.json', 'lemmatized.pkl', 'normalized_data.pkl', 'pos-tagged_lemmas.xlsx', 'pos_tags.xlsx', 'processed_data.json', 'processed_data.pkl', 'tf_idf.csv', 'tf_idf.xlsx']\n"
          ]
        }
      ],
      "source": [
        "print(sorted(os.listdir()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Сбор корпуса по  5 уровням английского языка: A1, A2, B1, B2, C1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создадим функцию, которая проходится по текстам в папке каждого уровня от A1 до C1 и собирает списки из текстов.\n",
        "\n",
        "def texts_bylevels():\n",
        "    path= os.getcwd()\n",
        "    levels = ['A1', 'A2', 'B1', 'B2', 'C1']\n",
        "    result = []\n",
        "\n",
        "    for level in levels:\n",
        "        folder_path = os.path.join(path, level)\n",
        "        texts = []\n",
        "\n",
        "        for file_name in sorted(os.listdir(folder_path)):\n",
        "            full_path = os.path.join(folder_path, file_name)\n",
        "            with open(full_path, 'r', encoding='utf-8') as file:\n",
        "                    texts.append(file.read())\n",
        "\n",
        "        result.append(texts)\n",
        "\n",
        "    return result[0], result[1], result[2], result[3], result[4]\n",
        "\n",
        "    \n",
        "A1, A2, B1, B2, C1 = texts_bylevels()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создаем словарь для объединенных текстов\n",
        "\n",
        "joined_texts = {\n",
        "    'A1': \"\\n\".join(A1),  \n",
        "    'A2': \"\\n\".join(A2),\n",
        "    'B1': \"\\n\".join(B1),\n",
        "    'B2': \"\\n\".join(B2),\n",
        "    'C1': \"\\n\".join(C1)\n",
        "}\n",
        "\n",
        "\n",
        "# И теперь извлекаем значения из словаря в отдельные переменные. В каждой переменной хранятся соединенные в один текст 40 текстов каждого уровня.\n",
        "\n",
        "joined_A1 = joined_texts['A1']\n",
        "joined_A2 = joined_texts['A2']\n",
        "joined_B1 = joined_texts['B1']\n",
        "joined_B2 = joined_texts['B2']\n",
        "joined_C1 = joined_texts['C1']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Все этапы предобработки текста до уровня лемм соберем в одну удобную функцию с выводом двух результатов: 1) токены, 2) леммы."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создадим функцию обработки текстов для определения лемм\n",
        "\n",
        "from stanza import DownloadMethod\n",
        "nlp_stanza = stanza.Pipeline(lang = \"en\",\n",
        "                             processors=\"tokenize, pos, lemma, ner, depparse\", tokenize_pretokenized=True, tokenize_no_ssplit=True,\n",
        "                             download_method=DownloadMethod.REUSE_RESOURCES, # чтобы сэкономить производительные силы компьютера\n",
        "                             verbose = False) # убирает лишние логи\n",
        "\n",
        "\n",
        "def normalize(text):\n",
        "    \n",
        "     # Воспользуемся spacy для удаления именованных сущностей из текста, пока он един (нам нужен контекст)  \n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # ИИ подсказал алгоритм, с помощью которого можно склеить токены текста после удаления именованных сущностей без больших пробелов\n",
        "    # (особенно в словах с апострофом) без использования многочисленных регулярных выражений\n",
        "\n",
        "    tokens = []\n",
        "    spaces = []\n",
        "\n",
        "    for token in doc:\n",
        "        if not token.ent_type_: \n",
        "            tokens.append(token.text)\n",
        "            spaces.append(bool(token.whitespace_))\n",
        "    \n",
        "\n",
        "     \n",
        "    doc_cleaned = Doc(nlp.vocab, words=tokens, spaces=spaces)\n",
        "    noent = doc_cleaned.text                                     # Получили текст без именованных сущностей\n",
        "\n",
        "\n",
        "    # Следующим этапом с помощью RegexpTokenizer уберем пунктуацию и разделим слова на токены\n",
        "    # Так как в тексте много слов с типографским апострофом \" ’ \", заменим его на обычный \" ' \" для удобной чистки\n",
        "\n",
        "    text_1 = noent.replace(\"’\", \"'\")\n",
        "    pattern = r\"\\w+(?:'\\w+)?\"\n",
        "    tokenizer = RegexpTokenizer(pattern)\n",
        "\n",
        "    tokenized_text = tokenizer.tokenize(text_1)\n",
        "\n",
        "    # Почистим текст от стоп-слов (загрузим список стоп-слов и добавим к нему еще слова)\n",
        "\n",
        "    stop_words = stopwords.words('english') + ['pm', 'mr', 'mrs', 'hi', 'wifi', 'oh']\n",
        "\n",
        "    lower_tokens = [token.lower() for token in tokenized_text]    # Токены текста без именованных сущностей в нижнем регистре\n",
        "    clean_tokens = []\n",
        "    for word in lower_tokens:\n",
        "        if word not in stop_words and word.isalpha():\n",
        "            clean_tokens.append(word)\n",
        "                \n",
        "    if not clean_tokens:                             # Если после очистки токенов не осталось\n",
        "        return{'tokens': [], 'lemmas': []}           # Возвращаем пустые списки\n",
        "    \n",
        "    # Наконец, получаем список лемм\n",
        "    \n",
        "    doc = nlp_stanza([clean_tokens])  \n",
        "    lemmas = [word.lemma.lower() for sent in doc.sentences for word in sent.words]  \n",
        "    \n",
        "    return{'tokens': clean_tokens, 'lemmas' : lemmas}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [19:45<00:00, 237.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalized_data.pkl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Обработаем все тексты функцией normalize, чтобы получить списки токенов и лемм для дальнейшей работы с ними, \n",
        "# а также сохраним их в формате pickle, чтобы потом оттуда выгружать данные и не тратить каждый раз производительные силы компьютера.\n",
        "\n",
        "def normalizing_levels(joined_texts, output_file='normalized_data.pkl'):\n",
        "    \n",
        "    normalized_results = {} # Создаем словарь, куда будем выгружать результаты\n",
        "    \n",
        "    for level, text in tqdm(joined_texts.items()):\n",
        "        normalized_results[level] = normalize(text)  \n",
        "    \n",
        "# Сохраняем в файл pickle\n",
        "\n",
        "    with open(output_file, 'wb') as f:\n",
        "        pickle.dump(normalized_results, f)\n",
        "    \n",
        "    print(f\"{output_file}\")\n",
        "    return normalized_results\n",
        "\n",
        "\n",
        "# Запустим обработку и сохранение\n",
        "\n",
        "normalized_results = normalizing_levels(joined_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создадим функцию, которая будет загружать сохраненные данные и возвращать отдельно токены и леммы\n",
        "\n",
        "def load_and_extract(file_path='normalized_data.pkl'):\n",
        "    \n",
        "    with open(file_path, 'rb') as f: # так как pickle - бинарный формат данных (он быстрее обрабатывается), то сохраняем их в режиме rb\n",
        "         data = pickle.load(f)\n",
        "    \n",
        "    \n",
        "    # Извлекаем токены и леммы для каждого уровня\n",
        "\n",
        "    tokens = {level: data[level]['tokens'] for level in data}\n",
        "    lemmas = {level: data[level]['lemmas'] for level in data}\n",
        "    \n",
        "    return tokens, lemmas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Подсчет показателя TTR (type-token ratio), то есть коэффициента лексического разнообразия."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Level  Total  Unique   TTR\n",
            "0    A1   3667     853  23.3\n",
            "1    A2   5361    1305  24.3\n",
            "2    B1   6349    2001  31.5\n",
            "3    B2   8950    2762  30.9\n",
            "4    C1  10381    3324  32.0\n"
          ]
        }
      ],
      "source": [
        "# Создаём таблицу\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        'Level': level,\n",
        "        'Total': len(normalized_data[level]['lemmas']),           # Подсчет общего количества лемм\n",
        "        'Unique': len(set((normalized_data[level]['lemmas'])))    # Подсчет уникальных лемм\n",
        "    }\n",
        "    for level in ['A1', 'A2', 'B1', 'B2', 'C1']\n",
        "])\n",
        "\n",
        "# Вычислим показатель TTR\n",
        "df['TTR'] = (df['Unique'] / df['Total'] * 100).round(1)           # Считаем показатель TTR: разделим общее количество лемм на количество уникальных лемм, округлим\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как видно из показателя, уровень лексического разнообразия растет с повышением уровня английского языка."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Синтаксический разбор."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Для анализа синтаксической сложности текстов каждого уровня будем использовать Stanza с названиями зависимостей в формате Universal Dependencies.\n",
        "\n",
        "def analyzing_dependencies(doc):\n",
        "        \n",
        "    counters = {\n",
        "               \n",
        "        # Синтаксическая сложность\n",
        "        'conj': 0,        # союзы (сложные предложения)\n",
        "        'advcl': 0,       # обстоятельственные придаточные\n",
        "        'acl': 0,         # определительные придаточные\n",
        "        'ccomp': 0,       # дополнительные придаточные\n",
        "        'xcomp': 0,       # открытые дополнения \n",
        "        \n",
        "        # Морфология и времена\n",
        "        'aux': 0,         # вспомогательные глаголы\n",
        "        'auxpass': 0,     # пассивные конструкции\n",
        "        'cop': 0,         # глаголы-связки (is, seem)\n",
        "        'modals': 0,      # модальные глаголы (can, should)\n",
        "        \n",
        "        # Лексика\n",
        "        'compound': 0,    # составные слова\n",
        "                \n",
        "        # Статистика\n",
        "        'avg_sent_len': sum(len(s.words) for s in doc.sentences) / len(doc.sentences),  # средняя длина предложения\n",
        "        'total_words': sum(len(s.words) for s in doc.sentences),                        # всего слов\n",
        "        'unique_words': len({w.text.lower() for s in doc.sentences for w in s.words}),  # количество уникальных слов\n",
        "    }\n",
        "    \n",
        "    # Подсчет зависимостей\n",
        "    for sentence in doc.sentences:\n",
        "        for word in sentence.words:\n",
        "                           \n",
        "            # Синтаксис\n",
        "            if word.deprel == 'conj':\n",
        "                counters['conj'] += 1\n",
        "            elif word.deprel == 'advcl':\n",
        "                counters['advcl'] += 1\n",
        "            elif word.deprel == 'acl':\n",
        "                counters['acl'] += 1\n",
        "            elif word.deprel == 'ccomp':\n",
        "                counters['ccomp'] += 1\n",
        "            elif word.deprel == 'xcomp':\n",
        "                counters['xcomp'] += 1\n",
        "            \n",
        "            \n",
        "            # Глаголы и времена\n",
        "            elif word.deprel == 'aux':\n",
        "                counters['aux'] += 1\n",
        "            elif word.deprel == 'auxpass':\n",
        "                counters['auxpass'] += 1\n",
        "            elif word.deprel == 'cop':\n",
        "                counters['cop'] += 1\n",
        "            elif word.upos == 'AUX' and word.text.lower() in {'can', 'could', 'may', 'might', 'must', 'shall', 'should', 'will', 'would'}:\n",
        "                counters['modals'] += 1\n",
        "            \n",
        "            # Лексика\n",
        "            elif word.deprel == 'compound':\n",
        "                counters['compound'] += 1\n",
        "\n",
        "    return counters\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [14:06<00:00, 169.39s/it]\n"
          ]
        }
      ],
      "source": [
        "# Пройдемся по текстам всех уровней и применим к ним функцию анализа зависимостей\n",
        "results = {}\n",
        "for level, text in tqdm(joined_texts.items()):\n",
        "    doc = nlp_stanza(text)                        \n",
        "    results[level] = analyzing_dependencies(doc)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохраним результаты анализа\n",
        "\n",
        "with open('analyzing_dependencies.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(results, f, ensure_ascii=False, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Откроем результаты(при последующем открытии файла):\n",
        "\n",
        "with open('analyzing_dependencies.json', 'r', encoding='utf-8') as f:\n",
        "    loaded_results = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_d12ee_row0_col13, #T_d12ee_row0_col14 {\n",
              "  background-color: #f7fbff;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_d12ee_row1_col13 {\n",
              "  background-color: #d8e7f5;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_d12ee_row1_col14 {\n",
              "  background-color: #a1cbe2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_d12ee_row2_col13 {\n",
              "  background-color: #1460a8;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_d12ee_row2_col14 {\n",
              "  background-color: #87bddc;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_d12ee_row3_col13, #T_d12ee_row4_col14 {\n",
              "  background-color: #08306b;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_d12ee_row3_col14 {\n",
              "  background-color: #125da6;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_d12ee_row4_col13 {\n",
              "  background-color: #2070b4;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_d12ee\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_d12ee_level0_col0\" class=\"col_heading level0 col0\" >total_words</th>\n",
              "      <th id=\"T_d12ee_level0_col1\" class=\"col_heading level0 col1\" >unique_words</th>\n",
              "      <th id=\"T_d12ee_level0_col2\" class=\"col_heading level0 col2\" >avg_sent_len</th>\n",
              "      <th id=\"T_d12ee_level0_col3\" class=\"col_heading level0 col3\" >conj</th>\n",
              "      <th id=\"T_d12ee_level0_col4\" class=\"col_heading level0 col4\" >advcl</th>\n",
              "      <th id=\"T_d12ee_level0_col5\" class=\"col_heading level0 col5\" >acl</th>\n",
              "      <th id=\"T_d12ee_level0_col6\" class=\"col_heading level0 col6\" >ccomp</th>\n",
              "      <th id=\"T_d12ee_level0_col7\" class=\"col_heading level0 col7\" >xcomp</th>\n",
              "      <th id=\"T_d12ee_level0_col8\" class=\"col_heading level0 col8\" >aux</th>\n",
              "      <th id=\"T_d12ee_level0_col9\" class=\"col_heading level0 col9\" >auxpass</th>\n",
              "      <th id=\"T_d12ee_level0_col10\" class=\"col_heading level0 col10\" >cop</th>\n",
              "      <th id=\"T_d12ee_level0_col11\" class=\"col_heading level0 col11\" >modals</th>\n",
              "      <th id=\"T_d12ee_level0_col12\" class=\"col_heading level0 col12\" >compound</th>\n",
              "      <th id=\"T_d12ee_level0_col13\" class=\"col_heading level0 col13\" >lexical_diversity</th>\n",
              "      <th id=\"T_d12ee_level0_col14\" class=\"col_heading level0 col14\" >complexity_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_d12ee_level0_row0\" class=\"row_heading level0 row0\" >A1</th>\n",
              "      <td id=\"T_d12ee_row0_col0\" class=\"data row0 col0\" >8593.00</td>\n",
              "      <td id=\"T_d12ee_row0_col1\" class=\"data row0 col1\" >2083.00</td>\n",
              "      <td id=\"T_d12ee_row0_col2\" class=\"data row0 col2\" >26.36</td>\n",
              "      <td id=\"T_d12ee_row0_col3\" class=\"data row0 col3\" >474.00</td>\n",
              "      <td id=\"T_d12ee_row0_col4\" class=\"data row0 col4\" >134.00</td>\n",
              "      <td id=\"T_d12ee_row0_col5\" class=\"data row0 col5\" >29.00</td>\n",
              "      <td id=\"T_d12ee_row0_col6\" class=\"data row0 col6\" >99.00</td>\n",
              "      <td id=\"T_d12ee_row0_col7\" class=\"data row0 col7\" >153.00</td>\n",
              "      <td id=\"T_d12ee_row0_col8\" class=\"data row0 col8\" >104.00</td>\n",
              "      <td id=\"T_d12ee_row0_col9\" class=\"data row0 col9\" >0.00</td>\n",
              "      <td id=\"T_d12ee_row0_col10\" class=\"data row0 col10\" >314.00</td>\n",
              "      <td id=\"T_d12ee_row0_col11\" class=\"data row0 col11\" >1.00</td>\n",
              "      <td id=\"T_d12ee_row0_col12\" class=\"data row0 col12\" >250.00</td>\n",
              "      <td id=\"T_d12ee_row0_col13\" class=\"data row0 col13\" >0.24</td>\n",
              "      <td id=\"T_d12ee_row0_col14\" class=\"data row0 col14\" >889.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d12ee_level0_row1\" class=\"row_heading level0 row1\" >A2</th>\n",
              "      <td id=\"T_d12ee_row1_col0\" class=\"data row1 col0\" >12406.00</td>\n",
              "      <td id=\"T_d12ee_row1_col1\" class=\"data row1 col1\" >3110.00</td>\n",
              "      <td id=\"T_d12ee_row1_col2\" class=\"data row1 col2\" >31.17</td>\n",
              "      <td id=\"T_d12ee_row1_col3\" class=\"data row1 col3\" >577.00</td>\n",
              "      <td id=\"T_d12ee_row1_col4\" class=\"data row1 col4\" >318.00</td>\n",
              "      <td id=\"T_d12ee_row1_col5\" class=\"data row1 col5\" >67.00</td>\n",
              "      <td id=\"T_d12ee_row1_col6\" class=\"data row1 col6\" >221.00</td>\n",
              "      <td id=\"T_d12ee_row1_col7\" class=\"data row1 col7\" >274.00</td>\n",
              "      <td id=\"T_d12ee_row1_col8\" class=\"data row1 col8\" >311.00</td>\n",
              "      <td id=\"T_d12ee_row1_col9\" class=\"data row1 col9\" >0.00</td>\n",
              "      <td id=\"T_d12ee_row1_col10\" class=\"data row1 col10\" >342.00</td>\n",
              "      <td id=\"T_d12ee_row1_col11\" class=\"data row1 col11\" >2.00</td>\n",
              "      <td id=\"T_d12ee_row1_col12\" class=\"data row1 col12\" >343.00</td>\n",
              "      <td id=\"T_d12ee_row1_col13\" class=\"data row1 col13\" >0.25</td>\n",
              "      <td id=\"T_d12ee_row1_col14\" class=\"data row1 col14\" >1457.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d12ee_level0_row2\" class=\"row_heading level0 row2\" >B1</th>\n",
              "      <td id=\"T_d12ee_row2_col0\" class=\"data row2 col0\" >14276.00</td>\n",
              "      <td id=\"T_d12ee_row2_col1\" class=\"data row2 col1\" >4067.00</td>\n",
              "      <td id=\"T_d12ee_row2_col2\" class=\"data row2 col2\" >46.65</td>\n",
              "      <td id=\"T_d12ee_row2_col3\" class=\"data row2 col3\" >691.00</td>\n",
              "      <td id=\"T_d12ee_row2_col4\" class=\"data row2 col4\" >342.00</td>\n",
              "      <td id=\"T_d12ee_row2_col5\" class=\"data row2 col5\" >148.00</td>\n",
              "      <td id=\"T_d12ee_row2_col6\" class=\"data row2 col6\" >123.00</td>\n",
              "      <td id=\"T_d12ee_row2_col7\" class=\"data row2 col7\" >256.00</td>\n",
              "      <td id=\"T_d12ee_row2_col8\" class=\"data row2 col8\" >336.00</td>\n",
              "      <td id=\"T_d12ee_row2_col9\" class=\"data row2 col9\" >0.00</td>\n",
              "      <td id=\"T_d12ee_row2_col10\" class=\"data row2 col10\" >325.00</td>\n",
              "      <td id=\"T_d12ee_row2_col11\" class=\"data row2 col11\" >2.00</td>\n",
              "      <td id=\"T_d12ee_row2_col12\" class=\"data row2 col12\" >755.00</td>\n",
              "      <td id=\"T_d12ee_row2_col13\" class=\"data row2 col13\" >0.28</td>\n",
              "      <td id=\"T_d12ee_row2_col14\" class=\"data row2 col14\" >1560.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d12ee_level0_row3\" class=\"row_heading level0 row3\" >B2</th>\n",
              "      <td id=\"T_d12ee_row3_col0\" class=\"data row3 col0\" >17846.00</td>\n",
              "      <td id=\"T_d12ee_row3_col1\" class=\"data row3 col1\" >5255.00</td>\n",
              "      <td id=\"T_d12ee_row3_col2\" class=\"data row3 col2\" >58.13</td>\n",
              "      <td id=\"T_d12ee_row3_col3\" class=\"data row3 col3\" >838.00</td>\n",
              "      <td id=\"T_d12ee_row3_col4\" class=\"data row3 col4\" >530.00</td>\n",
              "      <td id=\"T_d12ee_row3_col5\" class=\"data row3 col5\" >222.00</td>\n",
              "      <td id=\"T_d12ee_row3_col6\" class=\"data row3 col6\" >202.00</td>\n",
              "      <td id=\"T_d12ee_row3_col7\" class=\"data row3 col7\" >379.00</td>\n",
              "      <td id=\"T_d12ee_row3_col8\" class=\"data row3 col8\" >487.00</td>\n",
              "      <td id=\"T_d12ee_row3_col9\" class=\"data row3 col9\" >0.00</td>\n",
              "      <td id=\"T_d12ee_row3_col10\" class=\"data row3 col10\" >411.00</td>\n",
              "      <td id=\"T_d12ee_row3_col11\" class=\"data row3 col11\" >1.00</td>\n",
              "      <td id=\"T_d12ee_row3_col12\" class=\"data row3 col12\" >773.00</td>\n",
              "      <td id=\"T_d12ee_row3_col13\" class=\"data row3 col13\" >0.29</td>\n",
              "      <td id=\"T_d12ee_row3_col14\" class=\"data row3 col14\" >2171.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_d12ee_level0_row4\" class=\"row_heading level0 row4\" >C1</th>\n",
              "      <td id=\"T_d12ee_row4_col0\" class=\"data row4 col0\" >22395.00</td>\n",
              "      <td id=\"T_d12ee_row4_col1\" class=\"data row4 col1\" >6304.00</td>\n",
              "      <td id=\"T_d12ee_row4_col2\" class=\"data row4 col2\" >39.71</td>\n",
              "      <td id=\"T_d12ee_row4_col3\" class=\"data row4 col3\" >964.00</td>\n",
              "      <td id=\"T_d12ee_row4_col4\" class=\"data row4 col4\" >554.00</td>\n",
              "      <td id=\"T_d12ee_row4_col5\" class=\"data row4 col5\" >251.00</td>\n",
              "      <td id=\"T_d12ee_row4_col6\" class=\"data row4 col6\" >281.00</td>\n",
              "      <td id=\"T_d12ee_row4_col7\" class=\"data row4 col7\" >391.00</td>\n",
              "      <td id=\"T_d12ee_row4_col8\" class=\"data row4 col8\" >605.00</td>\n",
              "      <td id=\"T_d12ee_row4_col9\" class=\"data row4 col9\" >0.00</td>\n",
              "      <td id=\"T_d12ee_row4_col10\" class=\"data row4 col10\" >516.00</td>\n",
              "      <td id=\"T_d12ee_row4_col11\" class=\"data row4 col11\" >2.00</td>\n",
              "      <td id=\"T_d12ee_row4_col12\" class=\"data row4 col12\" >854.00</td>\n",
              "      <td id=\"T_d12ee_row4_col13\" class=\"data row4 col13\" >0.28</td>\n",
              "      <td id=\"T_d12ee_row4_col14\" class=\"data row4 col14\" >2441.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x1a443acfe00>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Оформим результаты в датафрейм\n",
        "\n",
        "df_dependencies = pd.DataFrame.from_dict(results, orient='index')\n",
        "\n",
        "\n",
        "# Добавим сортировку столбцов, чтобы было все нагляднее\n",
        "\n",
        "column_order = [\n",
        "    # Статистика\n",
        "    'total_words', 'unique_words', 'avg_sent_len',\n",
        "    \n",
        "    # Синтаксическая сложность\n",
        "    'conj', 'advcl', 'acl', 'ccomp', 'xcomp',\n",
        "    \n",
        "    # Морфология и времена\n",
        "    'aux', 'auxpass', 'cop', 'modals',\n",
        "    \n",
        "    # Лексика\n",
        "    'compound'\n",
        "]\n",
        "df_dependencies = df_dependencies[column_order]\n",
        "\n",
        "# Посчитаем некоторые метрики\n",
        "\n",
        "df_dependencies['lexical_diversity'] = df_dependencies['unique_words'] / df_dependencies['total_words']  # Лексическое разнообразие\n",
        "df_dependencies['complexity_score'] = df_dependencies[['conj', 'advcl', 'acl', 'ccomp', 'xcomp']].sum(axis=1)  # Общий показатель сложности\n",
        "\n",
        "# Сохраним в разных форматах на всякий случай\n",
        "df_dependencies.to_csv('dependency_analysis.csv', float_format='%.2f')  \n",
        "df_dependencies.to_excel('dependency_analysis.xlsx', float_format='%.2f') \n",
        "\n",
        "# Наконец, оформим результаты в красивую табличку\n",
        "\n",
        "display(df_dependencies.style\n",
        "       .background_gradient(cmap='Blues', subset=['complexity_score', 'lexical_diversity'])\n",
        "       .format('{:.2f}', subset=pd.IndexSlice[:, df_dependencies.select_dtypes(include='number').columns]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Анализ текста уровня A1:\n",
            "Распределение частей речи:\n",
            "PRON: 1010\n",
            "AUX: 431\n",
            "VERB: 1068\n",
            "ADP: 828\n",
            "ADJ: 688\n",
            "NOUN: 1952\n",
            "INTJ: 46\n",
            "ADV: 421\n",
            "NUM: 113\n",
            "CCONJ: 398\n",
            "DET: 869\n",
            "SCONJ: 68\n",
            "PUNCT: 140\n",
            "PART: 156\n",
            "PROPN: 399\n",
            "SYM: 3\n",
            "X: 3\n",
            "\n",
            "Анализ текста уровня A2:\n",
            "Распределение частей речи:\n",
            "AUX: 696\n",
            "PRON: 1385\n",
            "NOUN: 2699\n",
            "VERB: 1762\n",
            "ADP: 1202\n",
            "PART: 279\n",
            "SCONJ: 227\n",
            "CCONJ: 517\n",
            "DET: 1057\n",
            "ADJ: 760\n",
            "ADV: 664\n",
            "PUNCT: 214\n",
            "PROPN: 670\n",
            "NUM: 194\n",
            "INTJ: 73\n",
            "SYM: 3\n",
            "X: 4\n",
            "\n",
            "Анализ текста уровня B1:\n",
            "Распределение частей речи:\n",
            "ADJ: 1210\n",
            "CCONJ: 596\n",
            "NOUN: 3353\n",
            "X: 6\n",
            "SCONJ: 258\n",
            "PRON: 1058\n",
            "VERB: 1719\n",
            "DET: 1445\n",
            "AUX: 799\n",
            "ADP: 1528\n",
            "ADV: 664\n",
            "PART: 319\n",
            "PROPN: 924\n",
            "NUM: 197\n",
            "PUNCT: 153\n",
            "INTJ: 46\n",
            "SYM: 1\n",
            "\n",
            "Анализ текста уровня B2:\n",
            "Распределение частей речи:\n",
            "NOUN: 4380\n",
            "SCONJ: 484\n",
            "DET: 1650\n",
            "VERB: 2324\n",
            "ADJ: 1601\n",
            "ADP: 1892\n",
            "AUX: 1092\n",
            "PUNCT: 176\n",
            "PART: 476\n",
            "PRON: 1339\n",
            "ADV: 926\n",
            "CCONJ: 700\n",
            "PROPN: 587\n",
            "NUM: 181\n",
            "INTJ: 37\n",
            "SYM: 1\n",
            "\n",
            "Анализ текста уровня C1:\n",
            "Распределение частей речи:\n",
            "ADJ: 1798\n",
            "PROPN: 841\n",
            "ADP: 2555\n",
            "NUM: 316\n",
            "DET: 2199\n",
            "NOUN: 5179\n",
            "ADV: 1330\n",
            "AUX: 1377\n",
            "PRON: 1827\n",
            "VERB: 2812\n",
            "SCONJ: 499\n",
            "PART: 501\n",
            "CCONJ: 860\n",
            "PUNCT: 250\n",
            "INTJ: 46\n",
            "X: 4\n",
            "SYM: 1\n"
          ]
        }
      ],
      "source": [
        "# Посчитаем POS- теги и частотность \n",
        "\n",
        "# Анализ текста\n",
        "\n",
        "data = []\n",
        "\n",
        "for level, text in joined_texts.items():\n",
        "    print(f'\\nАнализ текста уровня {level}:')\n",
        "    doc = nlp_stanza(text)\n",
        "    pos_counts = Counter([word.upos for sentence in doc.sentences for word in sentence.words])\n",
        "\n",
        "    print(\"Распределение частей речи:\")\n",
        "    for tag, count in pos_counts.items():\n",
        "        print(f\"{tag}: {count}\")\n",
        "        data.append([tag, count, level])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tag</th>\n",
              "      <th>count</th>\n",
              "      <th>level</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PRON</td>\n",
              "      <td>1010</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AUX</td>\n",
              "      <td>431</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VERB</td>\n",
              "      <td>1068</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ADP</td>\n",
              "      <td>828</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADJ</td>\n",
              "      <td>688</td>\n",
              "      <td>A1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>CCONJ</td>\n",
              "      <td>860</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>PUNCT</td>\n",
              "      <td>250</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>46</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>X</td>\n",
              "      <td>4</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>SYM</td>\n",
              "      <td>1</td>\n",
              "      <td>C1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>84 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      tag  count level\n",
              "0    PRON   1010    A1\n",
              "1     AUX    431    A1\n",
              "2    VERB   1068    A1\n",
              "3     ADP    828    A1\n",
              "4     ADJ    688    A1\n",
              "..    ...    ...   ...\n",
              "79  CCONJ    860    C1\n",
              "80  PUNCT    250    C1\n",
              "81   INTJ     46    C1\n",
              "82      X      4    C1\n",
              "83    SYM      1    C1\n",
              "\n",
              "[84 rows x 3 columns]"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Оформим результаты в табличку\n",
        "\n",
        "df_pos = pd.DataFrame(data, columns=['tag', 'count', 'level'])\n",
        "df_pos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# И сохраним ее\n",
        "\n",
        "df_pos.to_excel('pos_tags.xlsx', index=False)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "7. Подсчет и сравнение косинусных расстояний между текстами разных уровней английского языка."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Для подсчета косинусных расстояний создадим мешок слов для каждого уровня. \n",
        "# Для этого необходимо объединить леммы каждого уровня в одну строку.\n",
        "\n",
        "# Загружаем сохранённые данные\n",
        "with open('normalized_data.pkl', 'rb') as f:\n",
        "    normalized_data = pickle.load(f)\n",
        "\n",
        "# Соединяем леммы каждого уровня в одну строку\n",
        "lemmas_by_level = {\n",
        "    level: ' '.join(data['lemmas']) \n",
        "    for level, data in normalized_data.items()\n",
        "}\n",
        "\n",
        "# Подготовим данные для CountVectorizer\n",
        "\n",
        "levels = list(lemmas_by_level.keys())\n",
        "texts = list(lemmas_by_level.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5393"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Создаём модель мешка слов с помощью библиотеки sklearn\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer    # Импорт функции, которая создаст вектора мешка слов\n",
        "vectorizer = CountVectorizer()                                 # Сохраним в переменную\n",
        "X = vectorizer.fit_transform(texts)                            # Создадим модель мешка слов\n",
        "len(vectorizer.get_feature_names_out())                        # Количество уникальных лемм в нашей модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandon</th>\n",
              "      <th>abandonment</th>\n",
              "      <th>abdel</th>\n",
              "      <th>ability</th>\n",
              "      <th>abject</th>\n",
              "      <th>able</th>\n",
              "      <th>aboard</th>\n",
              "      <th>abroad</th>\n",
              "      <th>abruptly</th>\n",
              "      <th>absence</th>\n",
              "      <th>...</th>\n",
              "      <th>young</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zeppelin</th>\n",
              "      <th>zipped</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "      <th>ºc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5393 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   abandon  abandonment  abdel  ability  abject  able  aboard  abroad  \\\n",
              "0        0            0      0        0       0     0       0       0   \n",
              "1        0            0      0        1       0     2       0       1   \n",
              "2        0            0      2        2       0     6       0       0   \n",
              "3        1            0      0        2       1    13       0       2   \n",
              "4        6            1      0        7       0    10       1       0   \n",
              "\n",
              "   abruptly  absence  ...  young  youth  youthful  youtube  zeppelin  zipped  \\\n",
              "0         0        0  ...      6      0         0        0         0       0   \n",
              "1         0        0  ...      8      0         0        0         0       0   \n",
              "2         0        0  ...      3      0         0        0         0       0   \n",
              "3         0        1  ...      7      2         1        1         1       0   \n",
              "4         1        0  ...      7      0         0        0         0       1   \n",
              "\n",
              "   zombie  zone  zoo  ºc  \n",
              "0       0     0    1   0  \n",
              "1       1     1    2   1  \n",
              "2       1     0    0   0  \n",
              "3       0     2    0   0  \n",
              "4       0     0    0   0  \n",
              "\n",
              "[5 rows x 5393 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Оформим результаты в табличку\n",
        "\n",
        "text_vector = pd.DataFrame(columns = vectorizer.get_feature_names_out(), data = X.toarray())\n",
        "text_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.75070724]])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Создадим векторы\n",
        "\n",
        "vector_1 = [X.toarray()[0]]\n",
        "vector_2 = [X.toarray()[1]]\n",
        "cosine_similarity(vector_1, vector_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Нарисуем тепловой график с помощью seaborn для визуального представления данных\n",
        "\n",
        "matrix_alt = cosine_similarity(X.toarray())\n",
        "sns.heatmap(matrix, annot=True)\n",
        "\n",
        "# 0- минимальная схожесть, 1- максимальная\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Как видно из графика, самая минимальная схожесть с другими уровнями у уровня А1(0 на графике) - самого начального. Самая максимальная схожесть у уровней B2(3 на графике) и C1(4 на графике)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8. Посчитаем показатель tf-idf(term frequency-inverse document frequency).\n",
        "Tf-idf помогает оценить важность слов в текстах. Высокий tf-idf показывает, что слово редко встречается в других уровнях. Если он нулевой - слово есть во всех уровнях и оно неинформативно."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# С помощью импортированного TfidfVectorizer получим вектора лемм в текстах\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1),  # (1,1) означает униграммы\n",
        "                                   min_df=0.01,         # игнорирует слова, которые встречаются реже чем 1% текстов\n",
        "                                   max_df=0.9,           # игнорирует слова, которые встречаются в >90% текстов\n",
        "                                   token_pattern=r'\\b[a-zA-Z]{3,}\\b'  # Только слова из 3+ букв                                                 \n",
        "                                   ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Для более чистых результатов будем использовать списки лемм\n",
        "\n",
        "tokens, lemmas = load_and_extract('normalized_data.pkl')\n",
        "\n",
        "lemmatized_texts = {\n",
        "    level: ' '.join(level_lemmas)               # Объединяем леммы через пробел\n",
        "    for level, level_lemmas in lemmas.items()\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
              "\twith 8432 stored elements and shape (5, 5012)>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Преобразуем тексты в матрицу tf-idf\n",
        "\n",
        "texts_for_tfidf = [\n",
        "    lemmatized_texts['A1'],\n",
        "    lemmatized_texts['A2'],\n",
        "    lemmatized_texts['B1'],\n",
        "    lemmatized_texts['B2'],\n",
        "    lemmatized_texts['C1']\n",
        "]\n",
        "\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(texts_for_tfidf)\n",
        "tfidf_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abandon' 'abandonment' 'abdel' ... 'zombie' 'zone' 'zoo']\n",
            "\n",
            "Вектор TF-IDF для A1:\n",
            "[0.         0.         0.         ... 0.         0.         0.01543367]\n",
            "\n",
            "Вектор TF-IDF для A2:\n",
            "[0.         0.         0.         ... 0.01269144 0.01269144 0.02538288]\n",
            "\n",
            "Вектор TF-IDF для B1:\n",
            "[0.         0.         0.02460146 ... 0.00992415 0.         0.        ]\n",
            "\n",
            "Вектор TF-IDF для B2:\n",
            "[0.00642824 0.         0.         ... 0.         0.01285648 0.        ]\n",
            "\n",
            "Вектор TF-IDF для C1:\n",
            "[0.0368897  0.00762064 0.         ... 0.         0.         0.        ]\n"
          ]
        }
      ],
      "source": [
        "# Преобразуем разреженную матрицу (хранит только ненулевые значения) в плотную (все значения явные)\n",
        "\n",
        "npm_tfidf = tfidf_matrix.todense()\n",
        "\n",
        "# Создадим словарь, в котором ключи - это уровни A1-C1, а значения - tf-idf вектора\n",
        "\n",
        "document_vectors = {\n",
        "    'A1': np.array(npm_tfidf[0]).flatten(),\n",
        "    'A2': np.array(npm_tfidf[1]).flatten(),\n",
        "    'B1': np.array(npm_tfidf[2]).flatten(),\n",
        "    'B2': np.array(npm_tfidf[3]).flatten(),\n",
        "    'C1': np.array(npm_tfidf[4]).flatten()\n",
        "}\n",
        "\n",
        "# Выводим список всех слов, которые учитывает векторизатор\n",
        "\n",
        "print(tfidf_vectorizer.get_feature_names_out())\n",
        "\n",
        "# Печатаем tf-idf вектора для каждого уровня\n",
        "\n",
        "for level, vector in document_vectors.items():\n",
        "    print(f\"\\nВектор TF-IDF для {level}:\")\n",
        "    print(vector) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Теперь преобразуем все вектора в списки для удобства\n",
        "\n",
        "vectors_as_lists = {\n",
        "    level: vector.tolist() \n",
        "    for level, vector in document_vectors.items()\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создадим отдельные переменные для каждого уровня:\n",
        "\n",
        "x_a1 = vectors_as_lists['A1']\n",
        "x_a2 = vectors_as_lists['A2']\n",
        "x_b1 = vectors_as_lists['B1']\n",
        "x_b2 = vectors_as_lists['B2']\n",
        "x_c1 = vectors_as_lists['C1']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Оформим все в датафрейм\n",
        "\n",
        "df_tfidf = pd.DataFrame.from_dict(vectors_as_lists, orient='index')\n",
        "df_tfidf.columns = tfidf_vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abandon</th>\n",
              "      <th>abandonment</th>\n",
              "      <th>abdel</th>\n",
              "      <th>ability</th>\n",
              "      <th>abject</th>\n",
              "      <th>able</th>\n",
              "      <th>aboard</th>\n",
              "      <th>abroad</th>\n",
              "      <th>abruptly</th>\n",
              "      <th>absence</th>\n",
              "      <th>...</th>\n",
              "      <th>yolk</th>\n",
              "      <th>york</th>\n",
              "      <th>youth</th>\n",
              "      <th>youthful</th>\n",
              "      <th>youtube</th>\n",
              "      <th>zeppelin</th>\n",
              "      <th>zipped</th>\n",
              "      <th>zombie</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.01913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008862</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012691</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.031461</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012691</td>\n",
              "      <td>0.012691</td>\n",
              "      <td>0.025383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024601</td>\n",
              "      <td>0.013860</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041580</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009924</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B2</th>\n",
              "      <td>0.006428</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008978</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.058355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012856</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.015935</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.007968</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012856</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1</th>\n",
              "      <td>0.036890</td>\n",
              "      <td>0.007621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030053</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.042933</td>\n",
              "      <td>0.007621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5012 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     abandon  abandonment     abdel   ability    abject      able    aboard  \\\n",
              "A1  0.000000     0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
              "A2  0.000000     0.000000  0.000000  0.008862  0.000000  0.017725  0.000000   \n",
              "B1  0.000000     0.000000  0.024601  0.013860  0.000000  0.041580  0.000000   \n",
              "B2  0.006428     0.000000  0.000000  0.008978  0.007968  0.058355  0.000000   \n",
              "C1  0.036890     0.007621  0.000000  0.030053  0.000000  0.042933  0.007621   \n",
              "\n",
              "      abroad  abruptly   absence  ...      yolk     york     youth  youthful  \\\n",
              "A1  0.000000  0.000000  0.000000  ...  0.000000  0.01913  0.000000  0.000000   \n",
              "A2  0.012691  0.000000  0.000000  ...  0.031461  0.00000  0.000000  0.000000   \n",
              "B1  0.000000  0.000000  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
              "B2  0.012856  0.000000  0.007968  ...  0.000000  0.00000  0.015935  0.007968   \n",
              "C1  0.000000  0.007621  0.000000  ...  0.000000  0.00000  0.000000  0.000000   \n",
              "\n",
              "     youtube  zeppelin    zipped    zombie      zone       zoo  \n",
              "A1  0.000000  0.000000  0.000000  0.000000  0.000000  0.015434  \n",
              "A2  0.000000  0.000000  0.000000  0.012691  0.012691  0.025383  \n",
              "B1  0.000000  0.000000  0.000000  0.009924  0.000000  0.000000  \n",
              "B2  0.007968  0.007968  0.000000  0.000000  0.012856  0.000000  \n",
              "C1  0.000000  0.000000  0.007621  0.000000  0.000000  0.000000  \n",
              "\n",
              "[5 rows x 5012 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_tfidf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохраним табличку в двух форматах\n",
        "\n",
        "df_tfidf.to_csv('tf_idf.csv') \n",
        "df_tfidf.to_excel('tf_idf.xlsx', sheet_name='TF-IDF Results') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A1: {'forest': 0.23060407752580953, 'sister': 0.21779273988548678, 'bed': 0.2047687210067115, 'tree': 0.2047687210067115, 'cook': 0.18321411879547872}\n",
            "A2: {'witch': 0.18876854479141278, 'phone': 0.17724817566084553, 'exam': 0.16498871280049376, 'woman': 0.1506609493117187, 'artist': 0.14749057686968264}\n",
            "B1: {'include': 0.1524603642300034, 'photograph': 0.1290139666580671, 'robot': 0.11908981537667733, 'offer': 0.11781028145045717, 'professional': 0.11088026489454793}\n",
            "B2: {'company': 0.17506428637212137, 'body': 0.1334004884549222, 'business': 0.12568717995947176, 'social': 0.12568717995947176, 'cannabis': 0.11951455903277367}\n",
            "C1: {'paragraph': 0.19051598012540308, 'oil': 0.13269440315921727, 'however': 0.12880005597924843, 'human': 0.12880005597924843, 'feedback': 0.12296567454321418}\n"
          ]
        }
      ],
      "source": [
        "# Найдем топ-5 самых значимых слов для каждого уровня\n",
        "\n",
        "top_words_per_level = {}\n",
        "for level in df_tfidf.index:\n",
        "    top_words = df_tfidf.loc[level].nlargest(5)  # Топ-5 слов\n",
        "    top_words_per_level[level] = top_words\n",
        "    print(f\"{level}: {top_words.to_dict()}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
